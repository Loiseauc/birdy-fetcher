#!/usr/bin/env python

doc = """Fetcher.

Usage:
  fetcher --DB <database>... [-s <search>] [-d <db>...]
          [-F <format>...] [-n <nb>] [--nocache]
  fetcher (-h | --help)

Examples:
  fetcher --DB NCBI -d nucleotide -F gb -F fasta -s gene --DB PDB -F pdb -n 10

Options:
  -h --help        Show this screen.
  -d=<db>          NCBI and KEGG data bases [default: nucleotide pathway]
  -F=<format>      File format [default: pdb].
  -s=<search>      Search term [default: gene].
  -n=<nb>          File(s) per format [default: 10].
  --DB=<database>  data base.
  --nocache        reload all files

"""

from docopt import docopt
from Bio_Eutils import Entrez
from schema import Schema, And, Use, SchemaError, Optional

import random
import requests
import urllib.request
import logging


def id_NCBI(db, search, file_per_format, formats):
    """Fetches NCBI IDs.

    Retrieves IDs from specified NCBI data base like 'nucleotide'

    Args:
        db : NCBI data base
        search : keyword
        file_per_format : number of file per formats
        formats : List of formats

    Returns:
        A list of IDs corresponding on the 'search' keywards.
        For exemple :

        ['894216361', '894216359', '894216357', '894216355',
         '894216353', '894216351', '894216349', '894216348']
    """

    logging.info('Fetches NCBI IDs on %s database', db)

    Entrez.email = 'loiseauc48@gmail.com'
    nb_file = file_per_format * (len(formats))
    i = random.randint(1, 100)

    handle = Entrez.esearch(db=db, retmax=nb_file, retstart=i, term=search)
    pub_search = Entrez.read(handle)
    handle.close()

    return pub_search['IdList']


def id_PDB(cache):
    """Fetches PDB IDs.

    Retrieves all IDs from PDB data base.

    Args:
        cache : boulean, if True, reloads all IDs, if False,
            use IDs in file "PDB_ID.txt"

    Returns:
        A list of all IDs.
        For exemple :

        ['4Z1S', '4Z1X', '4Z1Y', '4Z24', '4Z25', '4Z26',
         '4Z28', '4Z29', '4Z2B', '4Z2F', '4Z2G', '4Z2H',
         '4Z2I', '4Z2J', '4Z2K', '4Z2L', '4Z2O', '4Z2P']
    """

    logging.info('Fetches PDB IDs')

    if cache:
        url = (
            'http://www.rcsb.org/pdb/rest/customReport.csv?pdbids=*&' +
            'customReportColumns=structureId&format=csv&service=wsfile')
        r = requests.get(url)
        IDs = r.text.split('"\n"')
        IDs[0] = IDs[0].split('"')
        IDs[0] = IDs[0][1]
        IDs[-1] = IDs[-1].split('"')
        IDs[-1] = IDs[-1][0]

        with open('ID/PDB_ID.txt', 'w') as f:
            for ID in IDs:
                output = ID + '\t'
                f.write(output)
        f.closed

        return IDs

    else:
        with open('ID/PDB_ID.txt', 'r') as f:
            ID = f.read()
            IDs = ID.split('\t')
        f.closed
        IDs = IDs[:-1]
        return IDs


def id_DSSP():
    """Fetches DSSP IDs.

    Retrieves all IDs from file "DSSP_ID.txt".

    Returns:
        A list of all IDs.
        For exemple :

        ['1cdt', '1cdu', '1cdw', '1cdy', '1cdz',
         '1ce0', '1ce1', '1ce2', '1ce3', '1ce4',
         '1ce5', '1ce6', '1ce7', '1ce8', '1ce9']
    """

    with open('ID/DSSP_ID.txt', 'r') as f:
        ID = f.read()
        IDs = ID.split('\t')
    f.closed
    IDs = IDs[:-1]
    return IDs


def id_KEGG(db, cache):
    """Fetches KEGG IDs.

    Retrieves all IDs from specified KEGG data base like 'pathway'.

    Args:
        db : KEGG database
        cache : boulean, if True, reloads all IDs, if False,
            use IDs in file "KEGG_(database)_ID.txt"

    Returns:
        A list of IDs corresponding on the databases.
        For exemple :

        ['path:map00072', 'path:map00073', 'path:map00100', 'path:map00120',
         'path:map00121', 'path:map00130', 'path:map00140', 'path:map00190',
         'path:map00195', 'path:map00196', 'path:map00220', 'path:map00230',
         'path:map00231', 'path:map00232', 'path:map00240', 'path:map00250']

    """
    logging.info('Fetches KEGG IDs on %s database', db)

    file_name = 'ID/KEGG_' + db + '_ID.txt'

    if cache:
        url = ('http://rest.kegg.jp/list/' + db)
        r = requests.get(url)

        IDs = []
        lines = r.text.split('\n')
        for line in lines:
            ID = line.split('\t')

            if ID[0] != '':
                IDs.append(ID[0])

        with open(file_name, 'w') as f:
            for ID in IDs:
                output = ID + '\t'
                f.write(output)
        f.closed

        return IDs

    else:
        with open(file_name, 'r') as f:
            ID = f.read()
            IDs = ID.split('\t')
        f.closed
        IDs = IDs[:-1]
        return IDs


def fetch_NCBI(db, IDs, formats, file_per_format):
    """Fetches datas about IDs

    Retrieves datas about IDs in specified formats in NCBI
    data bases, in random order and load it in "Result" directory

    Args:
        db : NCBI data base
        IDs : IDs list
        file_per_format : number of file per formats
        formats : List of formats
    """

    logging.info(
        'Fetches NCBI datas about IDs on %s database and %s format(s)',
        db, formats)

    Entrez.email = 'loiseauc48@gmail.com'
    rand_list = random.sample(list(range(len(IDs))), len(IDs))
    i = 0

    # Fetch matching entries
    for fmt in formats:
        extension = '.' + fmt
        for n in range(file_per_format):
            start = rand_list[i]
            handle = Entrez.efetch(
                db=db, id=IDs,
                retmax=1, retstart=start,
                rettype=fmt, retmode="text"
                )

            output = handle.read()
            num = IDs[start]
            file_name = 'Result/NCBI' + db + str(num) + extension
            with open(file_name, 'w') as f:
                f.write(output)
            f.closed
            i += 1
            handle.close()


def fetch_PDB_pdb(IDs, file_per_format):
    """Fetches datas about random IDs

    Retrieves datas about a random list of n IDs, in pdb formats,
    in PDB data bases and load it in "Result" directory. "n" is
    the number of files per formats
    --- /!\ gzipped format /!\ ---

    Args:
        IDs : IDs list
        file_per_format : number of files per formats
    """

    logging.info('Fetches PDB datas about IDs on pdb format')

    rand_list = random.sample(list(range(len(IDs))), file_per_format)

    for i in range(file_per_format):
        url = (
            'ftp://ftp.ebi.ac.uk/pub/databases/rcsb/pdb-remediated' +
            '/data/structures/divided/pdb/')
        ID = IDs[rand_list[i]]
        ID = ID.lower()
        code = ID[:-1]
        code = code[1:]
        url = url + code + '/pdb' + ID + '.ent.gz'
        file_name = 'Result/pdb' + ID + '.ent.gz'
        try:
            urllib.request.urlretrieve(url, file_name)
        except urllib.error.URLError:
            logging.error('ftp error with url %s on PDB database', url)


def fetch_PDB_mmCIF(IDs, file_per_format):
    """Fetches datas about random IDs

    Retrieves datas about a random list of n IDs, in mmCIF formats,
    in PDB data bases and load it in "Result" directory. "n" is
    the number of files per formats
    --- /!\ gzipped format /!\ ---

    Args:
        IDs : IDs list
        file_per_format : number of files per formats
    """

    logging.info('Fetches PDB datas about IDs on mmCIF format')

    rand_list = random.sample(list(range(len(IDs))), file_per_format)

    for i in range(file_per_format):
        url = (
            'ftp://ftp.ebi.ac.uk/pub/databases/rcsb/pdb-remediated' +
            '/data/structures/divided/mmCIF/')
        ID = IDs[rand_list[i]]
        ID = ID.lower()
        code = ID[:-1]
        code = code[1:]
        url = url + code + '/' + ID + '.cif.gz'
        file_name = 'Result/mmCIF' + ID + '.cif.gz'
        try:
            urllib.request.urlretrieve(url, file_name)
        except urllib.error.URLError:
            logging.error('ftp error with url %s on PDB database', url)


def fetch_KEGG(IDs, file_per_format):
    """Fetches datas about random IDs

    Retrieves datas about a random list of n IDs, in KEGG data
    bases and load it in "Result" directory. "n" is the number
    of files per formats

    Args:
        IDs : IDs list
        file_per_format : number of files per formats
    """

    logging.info('Fetches KEGG datas about IDs')

    rand_list = random.sample(list(range(len(IDs))), file_per_format)

    for i in range(file_per_format):
        url = 'http://rest.kegg.jp/get/'
        ID = IDs[rand_list[i]]
        url = url + ID
        r = requests.get(url)
        output = r.text
        extension = '.keg'
        file_name = 'Result/KEGG' + ID + extension
        with open(file_name, 'w') as f:
            f.write(output)
        f.closed


def fetch_DSSP(IDs, file_per_format):
    """Fetches datas about IDs

    Retrieves datas about a random list of n IDs in DSSP data base
    and load it in "Result" directory. "n" is the number of files
    per formats.

    Args:
        IDs : IDs list
        file_per_format : number of file per formats
    """

    logging.info('Fetches DSSP datas about IDs')

    rand_list = random.sample(list(range(len(IDs))), file_per_format)

    for i in range(file_per_format):
        ID = IDs[rand_list[i]]
        ID = ID.lower()
        url = ('ftp://ftp.cmbi.ru.nl/pub/molbio/data/dssp/' + ID + '.dssp')
        file_name = 'Result/DSSP' + ID + '.dssp'
        try:
            urllib.request.urlretrieve(url, file_name)
        except urllib.error.URLError:
            logging.error('ftp error with url %s on DSSP database', url)


def run_PDB(file_per_format, fmt, cache):
    """Result

    Manages fonctions about PDB database

    Args:
        file_per_format : number of files per formats
        fmt : List of formats
    """

    logging.info('PDB database')

    IDs = id_PDB(cache)
    count = True

    if 'pdb' in fmt:
        fetch_PDB_pdb(IDs, file_per_format)
        count = False

    if 'mmCIF' in fmt:
        fetch_PDB_mmCIF(IDs, file_per_format)
        count = False

    # Error messages
    if count:
        logging.error(
            'Formats %s anot alowed. Try with "pdb" or "mmCIF"',
            fmt)


def run_NCBI(formats, search, file_per_format, databases):
    """Result

    Checks databases and formats and manages fonctions about NCBI database

    Args:
        file_per_format : number of files per formats
        formats : List of formats
        search : keyword
        db : NCBI data base
    """

    logging.info('NCBI database')

    Kdb = [
        'protein', 'nucleotide', 'nuccore', 'nucgss', 'homologene',
        'popset', 'nucest', 'sequences', 'snp']
    dbs = []

    for database in Kdb:
        if database in databases:
            dbs.append(database)

    fmts = ['fasta', 'gp', 'est', 'gb']
    form = []
    for fmt in formats:
        if fmt in fmts:
            form.append(fmt)

    if form and dbs:
        for db in dbs:
            IDs = id_NCBI(db, search, file_per_format, form)
            fetch_NCBI(db, IDs, form, file_per_format)

    # Error messages
    elif dbs:
        logging.error(
            'Formats %s not alowed. Try with "fasta", "gp", "est", or "gb"',
            formats)
    elif form:
        logging.error(
            'Database %s not alowed. Try with "protein", "nucleotide",' +
            '"nuccore", "nucgss", "homologene", "popset", "nucest",' +
            '"sequences" or "snp"', databases)
    else:
        message = (
            'Formats and databases are not alowed. Expected' +
            'formats : "fasta", "gp", "est", "gb"; Expected databases :' +
            '"protein", "nucleotide", "nuccore", "nucgss", "homologene",' +
            '"popset", "nucest", "sequences", "snp"')
        logging.error(message)


def run_KEGG(databases, file_per_format, cache):
    """Result

    Checks databases and manages fonctions about KEGG database

    Args:
        file_per_format : number of files per formats
        databases : NCBI data base
    """

    logging.info('KEGG database')

    Kdb = [
        'pathway', 'brite', 'module', 'ko', 'genome', 'compound', 'glycan',
        'reaction', 'rpair', 'rclass', 'enzyme', 'disease', 'drug', 'dgroup',
        'environ', 'organism']
    dbs = []

    for database in Kdb:
        if database in databases:
            dbs.append(database)

    if dbs:
        for db in dbs:
            ID = id_KEGG(db, cache)
            fetch_KEGG(ID, file_per_format)

    # Error messages
    else:
        logging.error(
            'Databases %s not alowed. Try with "pathway", "brite",' +
            ' "module", "ko", "genome", "compound", "glycan", "reaction",' +
            ' "rpair", "rclass", "enzyme", "disease", "drug", "dgroup",' +
            ' "environ" or "organism"', database)


def run_DSSP(file_per_format):
    """Result

    Manages fonctions about DSSP database

    Args:
        file_per_format : number of files per formats

    """

    IDs = id_DSSP()
    fetch_DSSP(IDs, file_per_format)


def validation(args):
    """Data validation

    Checks arguments

    Args:
        args : all arguments

    Returns:
        right arguments
    """

    logging.info('Checks arguments')

    schema = Schema({
        '--DB': And(list),
        Optional('-s'): And(str, len),
        Optional('-n'): And(Use(int), lambda n: 1 <= n <= 99),
        Optional('-F'): And(list),
        Optional('--help'): bool,
        Optional('--nocache'): bool,
        Optional('-d'): And(list)})

    try:
        args = schema.validate(args)
    except SchemaError as e:
        exit(e)

    return args


def main():
    logging.basicConfig(
        filename='fetcher.log',
        format='%(asctime)s %(levelname)s:%(message)s',
        datefmt='%m/%d/%Y %I:%M:%S %p',
        level=logging.INFO)

    logging.info('Started')
    args = docopt(doc)
    args = validation(args)

    database = args['--DB']
    formats = args['-F']
    search = args['-s']
    file_per_format = int(args['-n'])
    db = args['-d']
    cache = args['--nocache']
    count = True

    if 'PDB' in database:
        run_PDB(file_per_format, formats, cache)
        count = False

    if 'NCBI' in database:
        run_NCBI(formats, search, file_per_format, db)
        count = False

    if 'KEGG' in database:
        run_KEGG(db, file_per_format, cache)
        count = False

    if 'DSSP' in database:
        run_DSSP(file_per_format)
        count = False

    # Error messages
    if count:
        message = (
            'Databases ' + database + ' not alowed. Try with "NCBI", ' +
            '"DSSP", "KEGG" or "PDB"')
        logging.error(message)

    logging.info('Finished')


if __name__ == "__main__":
    # execute only if run as a script
    main()
